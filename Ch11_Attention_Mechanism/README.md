# Attention Mechanism

Attention is a generalized pooling method with bias alignment over inputs.

### INDEX
- Attention Mechanism
- Sequence to Sequence with Attention Mechanism
- Transformer